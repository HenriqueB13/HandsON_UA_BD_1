{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Para rodar o código será necessário na célula 3 importar as tabelas que anexamos juntamente ao código"
      ],
      "metadata": {
        "id": "e8ojuXeMwmD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalação e configuração do ambiente\n",
        "\n",
        " Esta célula configura o ambiente necessário para execução do Apache Spark no Google Colab.\n",
        "\n",
        "  - Instalação do Apache Spark 3.5\n",
        "  - Configuração do Java 8\n",
        "  - Download do MongoDB Spark Connector\n",
        "\n",
        " Nesta fase inicia-se a parte prática do pipeline de dados, onde a infraestrutura distribuída é preparada para integrar\n",
        " múltiplas fontes (MongoDB + CSV) e executar operações paralelas."
      ],
      "metadata": {
        "id": "ta1xsH5toMTF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CÉLULA 1: Instalação e COnfiguração do Spark e MongoDB\n",
        "print(\" Configurando ambiente Spark...\")\n",
        "\n",
        "!pip install findspark pymongo pyspark\n",
        "\n",
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.5.0/spark-3.5.0-bin-hadoop3.tgz\n",
        "!tar xf spark-3.5.0-bin-hadoop3.tgz\n",
        "\n",
        "!wget -q https://repo1.maven.org/maven2/org/mongodb/spark/mongo-spark-connector_2.12/3.0.1/mongo-spark-connector_2.12-3.0.1.jar\n",
        "\n",
        "print(\" Downloads concluídos!\")\n",
        "\n",
        "# Configuração do ambiente\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.0-bin-hadoop3\"\n",
        "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = \"\"\"\n",
        "--jars /content/mongo-spark-connector_2.12-3.0.1.jar\n",
        "--packages org.mongodb.spark:mongo-spark-connector_2.12:3.0.1\n",
        "pyspark-shell\n",
        "\"\"\"\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "print(\" Ambiente Spark configurado com sucesso!\")"
      ],
      "metadata": {
        "id": "4T75Lzyb6ofG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cd7b6f6-6c9a-4adb-e49d-1d4596f2878f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Configurando ambiente Spark...\n",
            "Collecting findspark\n",
            "  Downloading findspark-2.0.1-py2.py3-none-any.whl.metadata (352 bytes)\n",
            "Collecting pymongo\n",
            "  Downloading pymongo-4.15.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (22 kB)\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.12/dist-packages (3.5.1)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo)\n",
            "  Downloading dnspython-2.8.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.12/dist-packages (from pyspark) (0.10.9.7)\n",
            "Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
            "Downloading pymongo-4.15.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dnspython-2.8.0-py3-none-any.whl (331 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m331.1/331.1 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: findspark, dnspython, pymongo\n",
            "Successfully installed dnspython-2.8.0 findspark-2.0.1 pymongo-4.15.4\n",
            "Get:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:2 https://cli.github.com/packages stable InRelease\n",
            "Get:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:8 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,535 kB]\n",
            "Get:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
            "Get:10 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [6,008 kB]\n",
            "Get:11 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [83.6 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,286 kB]\n",
            "Hit:15 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:16 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,157 kB]\n",
            "Err:16 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages\n",
            "  File has unexpected size (2152857 != 2156739). Mirror sync in progress? [IP: 23.223.31.28 443]\n",
            "  Hashes of expected file:\n",
            "   - Filesize:2156739 [weak]\n",
            "   - SHA256:9ce5154d741d8a4a255dde74d306147646720668c380793025384b8479635c20\n",
            "   - SHA1:e90a6fef4ebddabc3e8d932df408c0493c38322d [weak]\n",
            "   - MD5Sum:680e66087ab28e802da3491909f00e46 [weak]\n",
            "  Release file created at: Mon, 01 Dec 2025 20:03:21 +0000\n",
            "Get:17 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,498 kB]\n",
            "Get:18 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [38.5 kB]\n",
            "Get:19 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,839 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,870 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,592 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [6,222 kB]\n",
            "Fetched 35.4 MB in 3s (10.3 MB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "E: Failed to fetch https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/Packages.gz  File has unexpected size (2152857 != 2156739). Mirror sync in progress? [IP: 23.223.31.28 443]\n",
            "   Hashes of expected file:\n",
            "    - Filesize:2156739 [weak]\n",
            "    - SHA256:9ce5154d741d8a4a255dde74d306147646720668c380793025384b8479635c20\n",
            "    - SHA1:e90a6fef4ebddabc3e8d932df408c0493c38322d [weak]\n",
            "    - MD5Sum:680e66087ab28e802da3491909f00e46 [weak]\n",
            "   Release file created at: Mon, 01 Dec 2025 20:03:21 +0000\n",
            "E: Some index files failed to download. They have been ignored, or old ones used instead.\n",
            " Downloads concluídos!\n",
            " Ambiente Spark configurado com sucesso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPLEMENTAÇÃO / INGESTÃO DE DADOS\n",
        "\n",
        "Carregamento de fonte complementar (CSV)\n",
        "\n",
        "importar os arquivos sql após executar a célula\n"
      ],
      "metadata": {
        "id": "kB-LU1Zrool-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bIFCRq7qiEbn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "de5ec5f1-3793-4cf0-dd7a-216b88a99c62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " FAÇA O UPLOAD DOS ARQUIVOS CSV:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-be487486-90d0-4df0-985c-0aac35eb5b48\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-be487486-90d0-4df0-985c-0aac35eb5b48\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving matriculas.csv to matriculas.csv\n",
            "Saving cursos.csv to cursos.csv\n",
            "Saving alunos.csv to alunos.csv\n",
            " Arquivos carregados:\n",
            "   - matriculas.csv (1407 bytes)\n",
            "   - cursos.csv (2072 bytes)\n",
            "   - alunos.csv (2402 bytes)\n"
          ]
        }
      ],
      "source": [
        "# CÉLULA 2: Upload do arquivos\n",
        "print(\" FAÇA O UPLOAD DOS ARQUIVOS CSV:\")\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "print(\" Arquivos carregados:\")\n",
        "for filename in uploaded.keys():\n",
        "    print(f\"   - {filename} ({len(uploaded[filename])} bytes)\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CÉLULA 3: Configuração do MongoBD e do Spark\n",
        "print(\" Configurando conexão com MongoDB...\")\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pymongo import MongoClient\n",
        "\n",
        "MONGODB_URI = \"mongodb+srv://usuario_spark:SenhaSegura123!@cluster-academico.hotgdc0.mongodb.net/\"\n",
        "DATABASE_NAME = \"sistema_academico\"\n",
        "COLLECTION_NAME = \"alunos\"\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"SistemaAcademico-MongoDB\") \\\n",
        "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "print(\" Spark Session criada!\")"
      ],
      "metadata": {
        "id": "iM3wR6xEYisH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a64835d-0adb-4468-bedd-98f16f0c0855"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Configurando conexão com MongoDB...\n",
            " Spark Session criada!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MIGRAÇÃO DE DADOS\n",
        "\n",
        "A célula implementa:\n",
        "  1. Leitura dos CSVs (relacional)\n",
        "  2. Construção dos documentos JSON\n",
        "  3. Criação da coleção \"alunos\" no MongoDB Atlas\n",
        "  4. Inserção de todos os documentos"
      ],
      "metadata": {
        "id": "yl1w9gh2pNDP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CÉLULA 4: Inserção de dados no MongoDB\n",
        "print(\" Inserindo dados no MongoDB Atlas...\")\n",
        "\n",
        "!pip install pymongo\n",
        "import pandas as pd\n",
        "import json\n",
        "from pymongo import MongoClient\n",
        "\n",
        "try:\n",
        "    client = MongoClient(MONGODB_URI)\n",
        "    db = client[DATABASE_NAME]\n",
        "    collection = db[COLLECTION_NAME]\n",
        "\n",
        "    print(\" Conectado ao MongoDB Atlas!\")\n",
        "\n",
        "    print(\" Carregando arquivos CSV...\")\n",
        "    df_alunos = pd.read_csv('alunos.csv', delimiter=';')\n",
        "    df_matriculas = pd.read_csv('matriculas.csv', delimiter=';')\n",
        "    df_cursos = pd.read_csv('cursos.csv', delimiter=';')\n",
        "\n",
        "    print(f\" Dados carregados: {len(df_alunos)} alunos, {len(df_matriculas)} matrículas, {len(df_cursos)} cursos\")\n",
        "\n",
        "    documentos_alunos = []\n",
        "\n",
        "    for index, aluno in df_alunos.iterrows():\n",
        "        matriculas_aluno = df_matriculas[df_matriculas['ALUNO_ID'] == aluno['ID']]\n",
        "\n",
        "        matriculas_array = []\n",
        "        for _, matricula in matriculas_aluno.iterrows():\n",
        "            curso_info = df_cursos[df_cursos['ID'] == matricula['CURSO_ID']]\n",
        "\n",
        "            if not curso_info.empty:\n",
        "                curso = curso_info.iloc[0]\n",
        "\n",
        "                nota = matricula['NOTA']\n",
        "                if pd.isna(nota) or str(nota) == '\\\\N':\n",
        "                    nota_num = None\n",
        "                else:\n",
        "                    try:\n",
        "                        nota_num = float(nota)\n",
        "                    except:\n",
        "                        nota_num = None\n",
        "\n",
        "                matricula_doc = {\n",
        "                    \"matricula_id\": int(matricula['ID']),\n",
        "                    \"curso_id\": int(matricula['CURSO_ID']),\n",
        "                    \"data_matricula\": matricula['DATA_MATRICULA'],\n",
        "                    \"status\": matricula['STATUS'],\n",
        "                    \"nota\": nota_num,\n",
        "                    \"curso_info\": {\n",
        "                        \"codigo\": curso['CODIGO'],\n",
        "                        \"nome\": curso['NOME'],\n",
        "                        \"descricao\": curso['DESCRICAO'],\n",
        "                        \"creditos\": int(curso['CREDITOS']),\n",
        "                        \"capacidade\": int(curso['CAPACIDADE'])\n",
        "                    }\n",
        "                }\n",
        "                matriculas_array.append(matricula_doc)\n",
        "\n",
        "        aluno_doc = {\n",
        "            \"aluno_id\": int(aluno['ID']),\n",
        "            \"numero_matricula\": int(aluno['NUMERO_MATRICULA']),\n",
        "            \"nome\": aluno['NOME'],\n",
        "            \"email\": aluno['EMAIL'],\n",
        "            \"data_nascimento\": aluno['DATA_NASCIMENTO'],\n",
        "            \"data_ingresso\": aluno['DATA_INGRESSO'],\n",
        "            \"status_aluno\": aluno['STATUS'],\n",
        "            \"matriculas\": matriculas_array,\n",
        "            \"total_matriculas\": len(matriculas_array),\n",
        "            \"matriculas_ativas\": len([m for m in matriculas_array if m['status'] == 'matriculado']),\n",
        "            \"matriculas_concluidas\": len([m for m in matriculas_array if m['status'] == 'concluido'])\n",
        "        }\n",
        "        documentos_alunos.append(aluno_doc)\n",
        "\n",
        "    if documentos_alunos:\n",
        "        collection.delete_many({})\n",
        "        result = collection.insert_many(documentos_alunos)\n",
        "        print(f\"✅ {len(result.inserted_ids)} documentos inseridos no MongoDB!\")\n",
        "\n",
        "        # Verificar\n",
        "        total_docs = collection.count_documents({})\n",
        "        print(f\" Total de documentos: {total_docs}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\" Erro: {e}\")"
      ],
      "metadata": {
        "id": "R4TvSG-DYXZ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88db4476-70e7-4e74-ff6d-cbfa98164b8e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Inserindo dados no MongoDB Atlas...\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.12/dist-packages (4.15.4)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from pymongo) (2.8.0)\n",
            " Conectado ao MongoDB Atlas!\n",
            " Carregando arquivos CSV...\n",
            " Dados carregados: 20 alunos, 20 matrículas, 20 cursos\n",
            "✅ 20 documentos inseridos no MongoDB!\n",
            " Total de documentos: 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Coleta de documentos diretamente do MongoDB Atlas\n",
        "- Conversão para Pandas e posteriormente para Spark DataFrame"
      ],
      "metadata": {
        "id": "TGKEUcMIpmay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CÉLULA 5: Carregar dados do MongoDB para o Spark\n",
        "\n",
        "try:\n",
        "    from pymongo import MongoClient\n",
        "    import pandas as pd\n",
        "\n",
        "    client = MongoClient(MONGODB_URI)\n",
        "    db = client[DATABASE_NAME]\n",
        "    collection = db[COLLECTION_NAME]\n",
        "\n",
        "    documents = list(collection.find())\n",
        "\n",
        "    if documents:\n",
        "        df_pandas = pd.DataFrame(documents)\n",
        "        if '_id' in df_pandas.columns:\n",
        "            df_pandas = df_pandas.drop('_id', axis=1)\n",
        "\n",
        "        df_mongodb = spark.createDataFrame(df_pandas)\n",
        "\n",
        "        print(f\" {df_mongodb.count()} documentos carregados do MongoDB!\")\n",
        "        print(\" Estrutura dos dados:\")\n",
        "        df_mongodb.printSchema()\n",
        "        df_mongodb.select(\"aluno_id\", \"nome\", \"status_aluno\", \"total_matriculas\").show(5, truncate=False)\n",
        "\n",
        "    else:\n",
        "        print(\" Nenhum documento encontrado\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\" Erro: {e}\")"
      ],
      "metadata": {
        "id": "2ZAlGOlY7d1A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33dea5ed-3628-42c3-9d8b-adb55574c108"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 20 documentos carregados do MongoDB!\n",
            " Estrutura dos dados:\n",
            "root\n",
            " |-- aluno_id: long (nullable = true)\n",
            " |-- numero_matricula: long (nullable = true)\n",
            " |-- nome: string (nullable = true)\n",
            " |-- email: string (nullable = true)\n",
            " |-- data_nascimento: string (nullable = true)\n",
            " |-- data_ingresso: string (nullable = true)\n",
            " |-- status_aluno: string (nullable = true)\n",
            " |-- matriculas: array (nullable = true)\n",
            " |    |-- element: map (containsNull = true)\n",
            " |    |    |-- key: string\n",
            " |    |    |-- value: long (valueContainsNull = true)\n",
            " |-- total_matriculas: long (nullable = true)\n",
            " |-- matriculas_ativas: long (nullable = true)\n",
            " |-- matriculas_concluidas: long (nullable = true)\n",
            "\n",
            "+--------+--------------+------------+----------------+\n",
            "|aluno_id|nome          |status_aluno|total_matriculas|\n",
            "+--------+--------------+------------+----------------+\n",
            "|1       |Ana Silva     |ativo       |2               |\n",
            "|2       |Bruno Oliveira|ativo       |2               |\n",
            "|3       |Carla Pereira |ativo       |1               |\n",
            "|4       |Diego Costa   |ativo       |1               |\n",
            "|5       |Érica Santos  |ativo       |1               |\n",
            "+--------+--------------+------------+----------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nesta célula, os arquivos CSV são carregados diretamente pelo Spark,\n",
        " formando DataFrames distribuídos que podem ser integrados com outras fontes.\n",
        " Essa etapa permite combinar o modelo relacional com o modelo NoSQL,"
      ],
      "metadata": {
        "id": "1igjF4gYpvLy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CÉLULA 6: Carregar CSV para Spark\n",
        "\n",
        "df_alunos_csv = spark.read.option(\"header\", \"true\").option(\"delimiter\", \";\").option(\"inferSchema\", \"true\").csv(\"alunos.csv\")\n",
        "df_cursos_csv = spark.read.option(\"header\", \"true\").option(\"delimiter\", \";\").option(\"inferSchema\", \"true\").csv(\"cursos.csv\")\n",
        "df_matriculas_csv = spark.read.option(\"header\", \"true\").option(\"delimiter\", \";\").option(\"inferSchema\", \"true\").csv(\"matriculas.csv\")\n",
        "\n",
        "print(\"✅ CSVs carregados:\")\n",
        "print(f\" Alunos: {df_alunos_csv.count()} registros\")\n",
        "print(f\" Cursos: {df_cursos_csv.count()} registros\")\n",
        "print(f\" Matrículas: {df_matriculas_csv.count()} registros\")"
      ],
      "metadata": {
        "id": "p2X-2Hlu8rzi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a15a83cd-6413-475e-98ca-6ff05d435429"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ CSVs carregados:\n",
            " Alunos: 20 registros\n",
            " Cursos: 20 registros\n",
            " Matrículas: 20 registros\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta célula implementa as operações centrais do pipeline:\n",
        "\n",
        "  1. JOIN entre matrículas, cursos e alunos\n",
        "  2. Uso de broadcast join para otimizar performance\n",
        "  3. Uso de cache() para reutilizar DataFrames sem recalcular"
      ],
      "metadata": {
        "id": "eEA8IDjip5e8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CÉLULA 7: Aplicar Otimizações e Joins\n",
        "\n",
        "from pyspark.sql.functions import col, broadcast\n",
        "\n",
        "df_mongodb.cache()\n",
        "df_cursos_csv.cache()\n",
        "\n",
        "print(f\" Cache aplicado: MongoDB={df_mongodb.is_cached}, Cursos={df_cursos_csv.is_cached}\")\n",
        "\n",
        "df_cursos_preparados = df_cursos_csv.select(\n",
        "    col(\"ID\").alias(\"CURSO_ID_JOIN\"),\n",
        "    col(\"CODIGO\").alias(\"CODIGO_CURSO\"),\n",
        "    col(\"NOME\").alias(\"NOME_CURSO\"),\n",
        "    col(\"CAPACIDADE\")\n",
        ")\n",
        "\n",
        "df_alunos_preparados = df_alunos_csv.select(\n",
        "    col(\"ID\").alias(\"ALUNO_ID_JOIN\"),\n",
        "    col(\"NUMERO_MATRICULA\"),\n",
        "    col(\"NOME\").alias(\"NOME_ALUNO\"),\n",
        "    col(\"STATUS\").alias(\"STATUS_ALUNO\")\n",
        ")\n",
        "\n",
        "df_completo = df_matriculas_csv.join(\n",
        "    broadcast(df_cursos_preparados),\n",
        "    df_matriculas_csv.CURSO_ID == df_cursos_preparados.CURSO_ID_JOIN\n",
        ").join(\n",
        "    df_alunos_preparados,\n",
        "    df_matriculas_csv.ALUNO_ID == df_alunos_preparados.ALUNO_ID_JOIN\n",
        ")\n",
        "\n",
        "print(f\" JOINs realizados: {df_completo.count()} registros\")\n",
        "print(\" Colunas disponíveis após JOIN:\")\n",
        "for coluna in df_completo.columns:\n",
        "    print(f\"   - {coluna}\")"
      ],
      "metadata": {
        "id": "cu3axXjA8wDV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b929f47a-fe14-4f6c-be1d-621478ff435e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Cache aplicado: MongoDB=True, Cursos=True\n",
            " JOINs realizados: 20 registros\n",
            " Colunas disponíveis após JOIN:\n",
            "   - ID\n",
            "   - ALUNO_ID\n",
            "   - CURSO_ID\n",
            "   - DATA_MATRICULA\n",
            "   - STATUS\n",
            "   - NOTA\n",
            "   - CRIADO_EM\n",
            "   - CURSO_ID_JOIN\n",
            "   - CODIGO_CURSO\n",
            "   - NOME_CURSO\n",
            "   - CAPACIDADE\n",
            "   - ALUNO_ID_JOIN\n",
            "   - NUMERO_MATRICULA\n",
            "   - NOME_ALUNO\n",
            "   - STATUS_ALUNO\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparar performance entre join normal e broadcast join\n",
        "\n",
        "   Mensurar melhoria em tempo de execução\n",
        "\n",
        " O Broadcast Join replica o DataFrame pequeno em todos os nós,\n",
        " eliminando shuffle e acelerando significativamente o JOIN."
      ],
      "metadata": {
        "id": "2SPgWhL7qBta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CÉLULA 8: Comparação de performace\n",
        "print(\" Comparando performance...\")\n",
        "\n",
        "import time\n",
        "from pyspark.sql.functions import broadcast\n",
        "\n",
        "inicio_tradicional = time.time()\n",
        "df_tradicional = df_matriculas_csv.join(df_cursos_csv, df_matriculas_csv.CURSO_ID == df_cursos_csv.ID)\n",
        "count_tradicional = df_tradicional.count()\n",
        "tempo_tradicional = time.time() - inicio_tradicional\n",
        "\n",
        "inicio_broadcast = time.time()\n",
        "df_broadcast = df_matriculas_csv.join(broadcast(df_cursos_csv), df_matriculas_csv.CURSO_ID == df_cursos_csv.ID)\n",
        "count_broadcast = df_broadcast.count()\n",
        "tempo_broadcast = time.time() - inicio_broadcast\n",
        "\n",
        "print(f\"RESULTADOS:\")\n",
        "print(f\"JOIN Tradicional: {tempo_tradicional:.3f} segundos\")\n",
        "print(f\"Broadcast JOIN: {tempo_broadcast:.3f} segundos\")\n",
        "print(f\"Melhoria: {((tempo_tradicional - tempo_broadcast) / tempo_tradicional * 100):.1f}% mais rápido\")"
      ],
      "metadata": {
        "id": "_VsXg2L99DlT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11b799af-43b6-4f55-e684-99c410309851"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Comparando performance...\n",
            "RESULTADOS:\n",
            "JOIN Tradicional: 0.545 segundos\n",
            "Broadcast JOIN: 0.469 segundos\n",
            "Melhoria: 14.0% mais rápido\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As células 9 a 12 realizam múltiplas análises de negócio:\n",
        "\n",
        "  • Cursos mais populares\n",
        "\n",
        "  • Desempenho acadêmico (médias, min, max)\n",
        "\n",
        "  • Perfil dos alunos\n",
        "\n",
        "  • Evolução temporal das matrículas\n",
        "\n",
        "\n",
        " Cada operação utiliza:\n",
        "  - groupBy()\n",
        "  - filtros condicionais\n",
        "  - agregações distribuídas"
      ],
      "metadata": {
        "id": "xgKT9SUvqS04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CÉLULA 9: Análise - Cursos mais populares\n",
        "\n",
        "from pyspark.sql.functions import count, when, expr, desc\n",
        "\n",
        "cursos_populares = df_completo.groupBy(\n",
        "    \"CODIGO_CURSO\", \"NOME_CURSO\", \"CAPACIDADE\"\n",
        ").agg(\n",
        "    count(\"*\").alias(\"total_matriculas\"),\n",
        "    expr(\"SUM(CASE WHEN STATUS = 'matriculado' THEN 1 ELSE 0 END)\").alias(\"matriculas_ativas\"),\n",
        "    expr(\"SUM(CASE WHEN STATUS = 'concluido' THEN 1 ELSE 0 END)\").alias(\"matriculas_concluidas\")\n",
        ").withColumn(\n",
        "    \"taxa_ocupacao\", (col(\"total_matriculas\") / col(\"CAPACIDADE\") * 100).cast(\"decimal(5,2)\")\n",
        ").orderBy(desc(\"total_matriculas\"))\n",
        "\n",
        "print(\" Top 10 cursos mais populares:\")\n",
        "cursos_populares.show(10, truncate=False)"
      ],
      "metadata": {
        "id": "CLhIRZgu4K41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93e0e931-5bf1-47e7-b443-b1b80065fffd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Top 10 cursos mais populares:\n",
            "+------------+------------------------+----------+----------------+-----------------+---------------------+-------------+\n",
            "|CODIGO_CURSO|NOME_CURSO              |CAPACIDADE|total_matriculas|matriculas_ativas|matriculas_concluidas|taxa_ocupacao|\n",
            "+------------+------------------------+----------+----------------+-----------------+---------------------+-------------+\n",
            "|PROG101     |Introdução à Programação|80        |5               |3                |2                    |6.25         |\n",
            "|BD101       |Banco de Dados          |50        |2               |1                |1                    |4.00         |\n",
            "|MAT101      |Matemática Básica       |60        |2               |0                |2                    |3.33         |\n",
            "|MAT201      |Cálculo I               |50        |2               |0                |2                    |4.00         |\n",
            "|MAT301      |Álgebra Linear          |45        |1               |0                |1                    |2.22         |\n",
            "|EMP101      |Empreendedorismo        |80        |1               |1                |0                    |1.25         |\n",
            "|ECO101      |Economia Básica         |70        |1               |0                |0                    |1.43         |\n",
            "|BIO101      |Biologia Geral          |40        |1               |0                |1                    |2.50         |\n",
            "|HIS101      |História Geral          |60        |1               |0                |1                    |1.67         |\n",
            "|PROJ101     |Gestão de Projetos      |60        |1               |1                |0                    |1.67         |\n",
            "+------------+------------------------+----------+----------------+-----------------+---------------------+-------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CÉLULA 10: Análise - desempenho acadêmico\n",
        "\n",
        "df_completo_nota = df_completo.withColumn(\"NOTA_NUM\",\n",
        "    when(col(\"NOTA\") == \"\\\\N\", None).otherwise(col(\"NOTA\").cast(\"double\")))\n",
        "\n",
        "desempenho_cursos = df_completo_nota.filter(\n",
        "    (col(\"STATUS\") == \"concluido\") & (col(\"NOTA_NUM\").isNotNull())\n",
        ").groupBy(\"CODIGO_CURSO\", \"NOME_CURSO\").agg(\n",
        "    expr(\"ROUND(AVG(NOTA_NUM), 2)\").alias(\"media_geral\"),\n",
        "    count(\"*\").alias(\"total_avaliados\"),\n",
        "    expr(\"ROUND(MIN(NOTA_NUM), 2)\").alias(\"nota_minima\"),\n",
        "    expr(\"ROUND(MAX(NOTA_NUM), 2)\").alias(\"nota_maxima\")\n",
        ").orderBy(desc(\"media_geral\"))\n",
        "\n",
        "print(\" Cursos com melhor desempenho:\")\n",
        "desempenho_cursos.show(truncate=False)"
      ],
      "metadata": {
        "id": "0UtD60jQ31zt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9a79d20-ef74-4881-b994-1a61f686c652"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Cursos com melhor desempenho:\n",
            "+------------+------------------------+-----------+---------------+-----------+-----------+\n",
            "|CODIGO_CURSO|NOME_CURSO              |media_geral|total_avaliados|nota_minima|nota_maxima|\n",
            "+------------+------------------------+-----------+---------------+-----------+-----------+\n",
            "|MAT201      |Cálculo I               |8.88       |2              |8.75       |9.0        |\n",
            "|BD101       |Banco de Dados          |8.4        |1              |8.4        |8.4        |\n",
            "|PROG101     |Introdução à Programação|8.15       |2              |7.2        |9.1        |\n",
            "|MAT301      |Álgebra Linear          |8.0        |1              |8.0        |8.0        |\n",
            "|EST101      |Estatística             |7.8        |1              |7.8        |7.8        |\n",
            "|MAT101      |Matemática Básica       |7.0        |2              |6.5        |7.5        |\n",
            "|BIO101      |Biologia Geral          |7.0        |1              |7.0        |7.0        |\n",
            "|HIS101      |História Geral          |6.9        |1              |6.9        |6.9        |\n",
            "+------------+------------------------+-----------+---------------+-----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CÉLULA 11: Análise - Perfil do aluno\n",
        "alunos_ativos = df_completo.groupBy(\n",
        "    \"NUMERO_MATRICULA\", \"NOME_ALUNO\", \"STATUS_ALUNO\"\n",
        ").agg(\n",
        "    count(\"*\").alias(\"total_matriculas\"),\n",
        "    expr(\"SUM(CASE WHEN STATUS = 'matriculado' THEN 1 ELSE 0 END)\").alias(\"cursando_atualmente\"),\n",
        "    expr(\"SUM(CASE WHEN STATUS = 'concluido' THEN 1 ELSE 0 END)\").alias(\"cursos_concluidos\")\n",
        ").filter(col(\"total_matriculas\") > 0).orderBy(desc(\"total_matriculas\"))\n",
        "\n",
        "print(\" Alunos com mais matrículas:\")\n",
        "alunos_ativos.show(10, truncate=False)"
      ],
      "metadata": {
        "id": "ApfQ7mHIYsQo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42f0d1d7-6359-4f79-fbe0-88108cb44b8d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Alunos com mais matrículas:\n",
            "+----------------+---------------+------------+----------------+-------------------+-----------------+\n",
            "|NUMERO_MATRICULA|NOME_ALUNO     |STATUS_ALUNO|total_matriculas|cursando_atualmente|cursos_concluidos|\n",
            "+----------------+---------------+------------+----------------+-------------------+-----------------+\n",
            "|20230001        |Ana Silva      |ativo       |2               |2                  |0                |\n",
            "|20230002        |Bruno Oliveira |ativo       |2               |0                  |2                |\n",
            "|20230011        |Kátia Fernandes|ativo       |1               |0                  |1                |\n",
            "|20230015        |Olivia Castro  |ativo       |1               |1                  |0                |\n",
            "|20230010        |João Martins   |ativo       |1               |0                  |1                |\n",
            "|20230014        |Nicolas Freitas|ativo       |1               |0                  |1                |\n",
            "|20230018        |Rafael Duarte  |ativo       |1               |0                  |1                |\n",
            "|20230005        |Érica Santos   |ativo       |1               |0                  |1                |\n",
            "|20230009        |Isabela Moreira|ativo       |1               |1                  |0                |\n",
            "|20230012        |Lucas Silva    |ativo       |1               |1                  |0                |\n",
            "+----------------+---------------+------------+----------------+-------------------+-----------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CÉLULA 12: Análise - Evolução temporal\n",
        "from pyspark.sql.functions import year\n",
        "\n",
        "evolucao_temporal = df_completo.withColumn(\"ano\", year(\"DATA_MATRICULA\")) \\\n",
        "    .groupBy(\"ano\").agg(\n",
        "        count(\"*\").alias(\"total_matriculas\"),\n",
        "        expr(\"SUM(CASE WHEN STATUS = 'concluido' THEN 1 ELSE 0 END)\").alias(\"concluidas\")\n",
        "    ).orderBy(\"ano\")\n",
        "\n",
        "print(\" Evolução das matrículas por ano:\")\n",
        "evolucao_temporal.show()"
      ],
      "metadata": {
        "id": "ykICyz8BdRbm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6c204e2-229c-4c6b-c242-5b063daaa44e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Evolução das matrículas por ano:\n",
            "+----+----------------+----------+\n",
            "| ano|total_matriculas|concluidas|\n",
            "+----+----------------+----------+\n",
            "|2019|               1|         0|\n",
            "|2020|               2|         2|\n",
            "|2021|               2|         2|\n",
            "|2022|               4|         4|\n",
            "|2023|               5|         3|\n",
            "|2024|               6|         0|\n",
            "+----+----------------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementa a etapa final do pipeline:\n",
        "\n",
        "  1. Salvamento dos DataFrames transformados em Parquet\n",
        "  2. Exportação para CSV"
      ],
      "metadata": {
        "id": "Q9Azu-EWs2cI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CÉLULA 13: Salvar resultados\n",
        "\n",
        "!mkdir -p /content/resultados\n",
        "\n",
        "cursos_populares.write.mode(\"overwrite\").parquet(\"/content/resultados/cursos_populares\")\n",
        "desempenho_cursos.write.mode(\"overwrite\").parquet(\"/content/resultados/desempenho_cursos\")\n",
        "alunos_ativos.write.mode(\"overwrite\").parquet(\"/content/resultados/alunos_ativos\")\n",
        "\n",
        "cursos_populares.toPandas().to_csv('cursos_populares.csv', index=False, encoding='utf-8')\n",
        "desempenho_cursos.toPandas().to_csv('desempenho_cursos.csv', index=False, encoding='utf-8')\n",
        "alunos_ativos.toPandas().to_csv('alunos_ativos.csv', index=False, encoding='utf-8')\n",
        "\n",
        "print(\" Resultados salvos!\")"
      ],
      "metadata": {
        "id": "PKfXqe_ldaHV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "435a6725-38da-45b1-b5fb-2cb4f2ad1e89"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Resultados salvos!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download\n"
      ],
      "metadata": {
        "id": "X3QRi6DytHKa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CÉLULA 14: Download\n",
        "print(\"Preparando download...\")\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "files.download('cursos_populares.csv')\n",
        "files.download('desempenho_cursos.csv')\n",
        "files.download('alunos_ativos.csv')\n",
        "\n",
        "print(\"Downloads prontos!\")"
      ],
      "metadata": {
        "id": "H6KfBn16dafA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "6e012d85-d390-4106-d560-fe88f4148f5f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparando download...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_014d9133-88e5-49d6-8889-b85e6994337a\", \"cursos_populares.csv\", 604)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_09b97043-4f0b-45b4-98e5-0224d9f0a7f2\", \"desempenho_cursos.csv\", 383)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_83e4eef6-01d4-4af0-9366-8a8e7c267a32\", \"alunos_ativos.csv\", 732)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloads prontos!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resumo automatizado de tudo que foi executado:\n",
        "#\n",
        "\n",
        "  • Conexão ao MongoDB\n",
        "\n",
        "  • Quantidade de documentos e dados carregados\n",
        "\n",
        "  • Otimizações aplicadas\n",
        "\n",
        "  • Resultados das análises"
      ],
      "metadata": {
        "id": "LvmhJnXKuN2l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CÉLULA 15: Resumo\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\" RELATÓRIO FINAL - MONGODB ATLAS + SPARK\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\" CONEXÃO E DADOS:\")\n",
        "print(f\"   • MongoDB Atlas: Conectado com sucesso\")\n",
        "print(f\"   • Documentos no MongoDB: {df_mongodb.count()}\")\n",
        "print(f\"   • Alunos no sistema: {df_alunos_csv.count()}\")\n",
        "print(f\"   • Cursos disponíveis: {df_cursos_csv.count()}\")\n",
        "\n",
        "print(f\"\\n OTIMIZAÇÕES:\")\n",
        "print(f\"   • Cache aplicado: Sim\")\n",
        "print(f\"   • Broadcast Join: {((tempo_tradicional - tempo_broadcast) / tempo_tradicional * 100):.1f}% mais rápido\")\n",
        "\n",
        "print(f\"\\n ANÁLISES REALIZADAS:\")\n",
        "print(\"   • Cursos mais populares\")\n",
        "print(\"   • Desempenho acadêmico\")\n",
        "print(\"   • Perfil dos alunos\")\n",
        "print(\"   • Evolução temporal\")\n",
        "\n",
        "print(f\"\\n RESULTADOS:\")\n",
        "print(\"   • Dados salvos em Parquet e CSV\")\n",
        "print(\"   • Downloads disponíveis\")\n",
        "print(\"    MongoDB como fonte principal\")\n",
        "print(\"    Spark para processamento\")\n",
        "print(\"    Otimizações aplicadas\")\n",
        "print(\"    Análises completas\")\n",
        "print(\"    Resultados exportados\")\n",
        "print(\"=\"*70)"
      ],
      "metadata": {
        "id": "cJkMtNU8dhap",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "567817c6-d49a-4478-fe9c-860eae950217"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            " RELATÓRIO FINAL - MONGODB ATLAS + SPARK\n",
            "======================================================================\n",
            " CONEXÃO E DADOS:\n",
            "   • MongoDB Atlas: Conectado com sucesso\n",
            "   • Documentos no MongoDB: 20\n",
            "   • Alunos no sistema: 20\n",
            "   • Cursos disponíveis: 20\n",
            "\n",
            " OTIMIZAÇÕES:\n",
            "   • Cache aplicado: Sim\n",
            "   • Broadcast Join: 14.0% mais rápido\n",
            "\n",
            " ANÁLISES REALIZADAS:\n",
            "   • Cursos mais populares\n",
            "   • Desempenho acadêmico\n",
            "   • Perfil dos alunos\n",
            "   • Evolução temporal\n",
            "\n",
            " RESULTADOS:\n",
            "   • Dados salvos em Parquet e CSV\n",
            "   • Downloads disponíveis\n",
            "    MongoDB como fonte principal\n",
            "    Spark para processamento\n",
            "    Otimizações aplicadas\n",
            "    Análises completas\n",
            "    Resultados exportados\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J5ao-zrlipoI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}